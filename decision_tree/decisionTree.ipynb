{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "credit_rating\n",
      "  fair\n",
      "    age\n",
      "      <=30\n",
      "        student\n",
      "          no\n",
      "            income\n",
      "              high -> no\n",
      "              medium -> no\n",
      "              low -> no\n",
      "          yes\n",
      "            income\n",
      "              low -> yes\n",
      "              high -> yes\n",
      "              medium -> yes\n",
      "      30..40\n",
      "        income\n",
      "          high\n",
      "            student\n",
      "              no -> yes\n",
      "              yes -> yes\n",
      "          low\n",
      "            student\n",
      "              yes -> no\n",
      "      >40\n",
      "        income\n",
      "          medium\n",
      "            student\n",
      "              no -> yes\n",
      "              yes -> yes\n",
      "          low -> yes\n",
      "          high -> no\n",
      "  excellent\n",
      "    income\n",
      "      high\n",
      "        age\n",
      "          <=30 -> no\n",
      "          >40\n",
      "            student\n",
      "              no -> no\n",
      "      low\n",
      "        age\n",
      "          >40\n",
      "            student\n",
      "              yes -> no\n",
      "              no -> yes\n",
      "          30..40\n",
      "            student\n",
      "              yes -> no\n",
      "          <=30 -> no\n",
      "      medium\n",
      "        age\n",
      "          <=30\n",
      "            student\n",
      "              yes -> yes\n",
      "              no -> yes\n",
      "          30..40\n",
      "            student\n",
      "              no -> yes\n",
      "              yes -> no\n",
      "          >40\n",
      "            student\n",
      "              no -> no\n",
      "              yes -> no\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "def entropy(probabilities):\n",
    "    return -sum(p * math.log2(p) if p != 0 else 0 for p in probabilities)\n",
    "\n",
    "def information_gain(data, split_attribute_name, target_name):\n",
    "    # Calculate the entropy of the entire dataset\n",
    "    total_entropy = entropy(data[target_name].value_counts(normalize=True))\n",
    "\n",
    "    # Calculate the weighted entropy of the splits\n",
    "    weighted_entropy = 0\n",
    "    for value in data[split_attribute_name].unique():\n",
    "        subset = data[data[split_attribute_name] == value]\n",
    "        weight = len(subset) / len(data)\n",
    "        value_counts = subset[target_name].value_counts(normalize=True)\n",
    "        subset_entropy = entropy(value_counts)\n",
    "        weighted_entropy += weight * subset_entropy\n",
    "\n",
    "    # Calculate information gain\n",
    "    info_gain = total_entropy - weighted_entropy\n",
    "    return info_gain\n",
    "\n",
    "def build_decision_tree(data, original_data, features, target_attribute_name, parent_node_class=None):\n",
    "    # If all target values are the same, return that value\n",
    "    if len(data[target_attribute_name].unique()) <= 1:\n",
    "        return data[target_attribute_name].unique()[0]\n",
    "\n",
    "    # If the dataset is empty or the features list is empty, return the most common target value\n",
    "    if len(data) == 0 or len(features) == 0:\n",
    "        return parent_node_class\n",
    "\n",
    "    # Determine the best splitting criterion (attribute)\n",
    "    information_gains = {}\n",
    "    for feature in features:\n",
    "        information_gains[feature] = information_gain(data, feature, target_attribute_name)\n",
    "\n",
    "    best_feature = max(information_gains, key=information_gains.get)\n",
    "\n",
    "    # Create the tree structure\n",
    "    tree = {best_feature: {}}\n",
    "\n",
    "    # Remove the best feature from the feature list\n",
    "    features = [f for f in features if f != best_feature]\n",
    "\n",
    "    # Expand the tree by recursively calling build_decision_tree\n",
    "    for value in data[best_feature].unique():\n",
    "        subset = data[data[best_feature] == value]\n",
    "        subtree = build_decision_tree(subset, data, features, target_attribute_name, data[target_attribute_name].mode()[0])\n",
    "        tree[best_feature][value] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "# Define the target attribute name\n",
    "target_attribute_name = 'buys_computer'\n",
    "\n",
    "# Get the list of features (excluding the target attribute)\n",
    "features = df.columns.tolist()\n",
    "features.remove(target_attribute_name)\n",
    "\n",
    "# Build the decision tree\n",
    "decision_tree = build_decision_tree(df, df, features, target_attribute_name)\n",
    "\n",
    "# Function to print the decision tree\n",
    "def print_decision_tree(tree, indent=\"\"):\n",
    "    for attribute, children in tree.items():\n",
    "        if isinstance(children, dict):\n",
    "            print(indent + attribute)\n",
    "            print_decision_tree(children, indent + \"  \")\n",
    "        else:\n",
    "            print(indent + attribute + \" -> \" + children)\n",
    "\n",
    "# Print the decision tree\n",
    "print_decision_tree(decision_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
